# お勧め機能（サービス推奨機能）のトリガーロジック

## 基本的な仕組み

お勧め機能（サービス推奨機能）は**「トリガーワード + LLMによる文脈分析」**という2段階の判断プロセスで動作しています。

### Step 1：トリガーワードの検出

まず、ユーザーメッセージに「トリガーワード」が含まれているかをチェックします。トリガーワードは`advice_patterns.js`ファイルの`explicitAdvicePatterns`配列で定義されています。これには以下のようなカテゴリの言葉が含まれます：

- 基本的なアドバイス要求：「アドバイスください」「教えてください」など
- おすすめ・サービス関連：「おすすめを教えて」「サービスある」など
- 丁寧な表現：「アドバイスいただけますか」など
- どうすれば系：「どうすればいいですか」「どうしたらいい」など
- 質問系：「質問があります」「教えて」など
- 助けて系：「助けて」「ヘルプください」など
- その他の明示的な表現：「アドバイス」「助言」「おすすめ」「お勧め」「オススメ」「提案」など

### Step 2：LLMによる文脈分析

トリガーワードが検出された場合、さらにLLM（具体的には`gpt-4o-mini`モデル）を使用して文脈を分析します。これは`analyzeShouldShowRecommendation`関数で実装されており、以下のような処理を行います：

1. まず高速なパターンマッチングで否定的フィードバック（「要らない」「いらない」など）がないかをチェック
2. 否定的フィードバックがなければ、OpenAI APIを呼び出し
3. LLMに対して「ユーザーの発言が「サービスやおすすめを求めている」のか、それとも「サービスやおすすめを拒否・否定している」のかを判断」するようプロンプトを設定
4. LLMからのレスポンス（`true`または`false`）に基づいて最終判断

### エラー処理とフォールバック

LLMの呼び出し中にエラーが発生した場合、システムはトリガーワードの存在だけに基づいて判断する（つまりトリガーワードがあれば`true`を返す）シンプルな判断にフォールバックします。

## コード実装

主要な実装は`server.js`ファイル内の以下の関数にあります：

1. `detectAdviceRequest(userMessage, history)` - トリガーワードの検出とLLM呼び出しの管理
2. `analyzeShouldShowRecommendation(userMessage, negativeFeedbackPatterns)` - LLMを使用した文脈分析

## 実際の動作例

1. ユーザーが「アドバイスお願いします」と入力
2. システムが「アドバイス」というトリガーワードを検出
3. コンソールに「Trigger word "アドバイス" found, analyzing context with LLM...」とログ出力
4. LLMが文脈を分析し、これがサービス推奨を求めていると判断
5. システムがサービス推奨を表示

## まとめ

このハイブリッドアプローチ（パターンマッチング + LLM分析）の利点：

1. **高速性と効率**: 明らかに否定的なフィードバックはパターンマッチングで高速に除外
2. **精度**: 微妙なニュアンスはLLMで正確に判断
3. **堅牢性**: LLMに問題があった場合のフォールバックメカニズム
4. **カスタマイズ性**: トリガーワードとプロンプトの調整で精度向上が可能

このように、お勧め機能のトリガーロジックは単純なパターンマッチングだけでなく、LLMの文脈理解能力を活用した高度な仕組みになっています。 