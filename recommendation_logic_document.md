# お勧め機能（サービス推奨機能）のトリガーロジック

## 基本的な仕組み

お勧め機能（サービス推奨機能）は**「純粋なLLMによる文脈理解」**を使用して動作するようになりました。以前は「トリガーワード + LLMによる文脈分析」という2段階の判断プロセスでしたが、より高度な理解を提供するために簡素化されました。

### LLMによる文脈理解

GPT-4o-miniモデルを使用して、ユーザーのメッセージ内容を分析し、以下を判断します：

1. ユーザーが明示的または暗黙的にアドバイスやサービスの推薦を求めているか
2. ユーザーが困った状況にあり、サポートが必要かどうか
3. 単なる雑談やお礼の場合は推薦を表示しないようにする
4. ユーザーが推薦を拒否している場合も推薦を表示しない

この判断は`detectAdviceRequestWithLLM`関数で実装されており、次のような処理を行います：

1. OpenAI APIを使用して、GPT-4o-miniモデルにユーザーのメッセージを送信
2. LLMに対して「ユーザーがアドバイスやサービスの推薦を求めているか、困った状況にあるかを判断」するようプロンプトを設定
3. LLMからのレスポンス（`yes`または`no`）に基づいて最終判断

### エラー処理とフォールバック

LLMの呼び出し中にエラーが発生した場合、より安全なアプローチとして、デフォルトで推薦を表示しないようにします。

## コード実装

主要な実装は`server.js`ファイル内の以下の関数にあります：

1. `detectAdviceRequest(userMessage, history)` - LLMによる文脈理解の起点
2. `detectAdviceRequestWithLLM(userMessage, history)` - GPT-4o-miniモデルを使用した実際の分析処理
3. `shouldShowServicesToday(userId, history, userMessage)` - 判断結果を使用した表示タイミングの制御

## 実際の動作例

1. ユーザーが「最近すごく困っていて...」と入力（特定のトリガーワードなし）
2. システムがLLMを使用して文脈を分析
3. LLMがユーザーが困った状況にあると判断
4. システムがサービス推薦を表示

## まとめ

このアプローチ（純粋なLLM文脈理解）の利点：

1. **自然性**: ユーザーは特定のトリガーワードを覚える必要がなく、より自然な会話ができる
2. **精度**: 暗黙的な要求や困難な状況も理解可能
3. **包括性**: 明示的な表現だけでなく、感情や文脈に埋め込まれたニーズも検出
4. **柔軟性**: LLMの性能向上に伴い、将来的に理解能力もアップデート可能

このように、お勧め機能のトリガーロジックはより高度化され、ユーザーがどのような言葉で表現しても、真のニーズを理解して適切なサービスを推薦できるようになりました。 